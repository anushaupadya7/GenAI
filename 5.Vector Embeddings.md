# 🧩 Vector Embeddings

Vector **embeddings** are numerical representations of data — such as **text, images, or audio** — that capture their **meaning** and **relationships** in a continuous vector space.  
They allow machines to compare **semantic similarity** instead of literal string equality.

---

## 📘 Example: Text Embeddings

| Word | Embedding (example 3D vector) |
|------|-------------------------------|
| “cat” | [0.21, 0.91, 0.33] |
| “dog” | [0.20, 0.85, 0.31] |
| “car” | [0.88, 0.12, 0.44] |

Here, the **distance** between “cat” and “dog” is smaller than between “cat” and “car,”  
meaning the model understands cats and dogs are semantically closer.

---

## ⚙️ How Are Embeddings Generated?

Embeddings are learned by **neural networks** during training.  

1. **Input:** “I love machine learning”  
2. **Tokenization:** → `["I", "love", "machine", "learning"]`  
3. **Mapping:** Each token → numerical vector using an **embedding layer**  
4. **Training:** The model adjusts vectors so similar meanings lie closer together

---

## 🧠 Where Are Embeddings Used?

| Application | Purpose |
|--------------|----------|
| **Search Engines** | Find semantically similar documents (not just exact matches) |
| **Chatbots / RAG Systems** | Retrieve relevant info based on meaning |
| **Recommendation Systems** | Suggest similar items or products |
| **Clustering & Classification** | Group similar data points together |

---

## 🔢 Mathematical Intuition

An embedding is a **vector** in an *n-dimensional space*.  
Similarity is often measured using **cosine similarity**:

\[
\text{similarity}(A, B) = \frac{A \cdot B}{||A|| \, ||B||}
\]

A value closer to `1` → more similar meaning.

---

## 🧭 Why Are Embeddings Powerful?

- Convert **discrete** data → **continuous** vector space  
- Capture **semantic meaning**  
- Enable arithmetic on meanings  

Example:  
\[
\text{vector}("king") - \text{vector}("man") + \text{vector}("woman") ≈ \text{vector}("queen")
\]

---

## 🗂️ Types of Embeddings

| Type | Example | Description |
|------|----------|-------------|
| **Word Embeddings** | Word2Vec, GloVe | Represent words in fixed-dimensional space |
| **Sentence Embeddings** | Sentence-BERT | Represent full sentences or paragraphs |
| **Document Embeddings** | doc2vec, OpenAI text-embedding models | Represent entire documents |
| **Multimodal Embeddings** | CLIP, DALL-E | Link text and images in same vector space |

---

## 🚀 In the Context of LLMs

Large Language Models (LLMs) like GPT use embeddings internally.

In **Retrieval-Augmented Generation (RAG)**:

1. Text data → embeddings  
2. User query → embedding  
3. Compare similarity using cosine distance  
4. Retrieve top results to provide context for model responses

---

## 📏 Vocabulary & Token IDs Connection

- Each token in a model’s **vocabulary** has a **token ID**  
- The **embedding matrix** maps each token ID to its vector  

If:
- Vocab size = 50,000  
- Embedding dimension = 768  

Then the embedding matrix = **50,000 × 768**

✅ Larger vocab → more expressive  
⚠️ But heavier model

---

## 🧩 Visualization Example

